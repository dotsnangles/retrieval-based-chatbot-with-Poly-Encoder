{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poly encoder training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvMLgi6SQKsbcJDl4ODXOs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/poly_encoder_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Poly-Encoder"
      ],
      "metadata": {
        "id": "DAEDgVE13tmn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "92a5237e-8632-4a4d-dee4-f188de4ec96e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "593adaf4-bb71-4e7e-ceae-87b92b27079b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul  4 11:01:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets folium==0.2.1 apex"
      ],
      "metadata": {
        "id": "pAcEd4LC1XkQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "9cf4bbb8-b83d-4d9f-f874-bc1adae192ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 84 (delta 12), reused 16 (delta 6), pack-reused 57\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Poly-Encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWr7HVEMMA2i",
        "outputId": "a7fe5d8c-db42-4f15-d824-105db75891f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, BertPreTrainedModel, BertModel, BertConfig, BertTokenizer\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, BertPreTrainedModel, BertModel, BertConfig, BertTokenizer, BertTokenizerFast\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from dataset import SelectionDataset\n",
        "from transform import SelectionSequentialTransform, SelectionJoinTransform, SelectionConcatTransform\n",
        "from encoder import PolyEncoder, BiEncoder, CrossEncoder\n",
        "\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "\n",
        "import logging"
      ],
      "metadata": {
        "id": "GhKdojJmGUPQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder 1uC1pSCrh9xlieF60z78QuCg7OxvU9kUs\n",
        "!mv /content/dstc7/*.json /content/Poly-Encoder/dstc7\n",
        "!mv /content/dstc7/*.tsv /content/Poly-Encoder/dstc7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edrW8JmxZWrb",
        "outputId": "7b7c9f02-bf5b-4bda-ae6f-dee70769d792"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1YXsj5U-P1nj3ID2ni62vvW4m_4AMYh_v ubuntu_dev_subtask_1.json\n",
            "Processing file 1I46tBMSYrDCFb0UoequBSl4Uqo0GOVms ubuntu_responses_subtask_1.tsv\n",
            "Processing file 1tHAe_WGFqQUHmdM28RttlVsYukL69qtg ubuntu_test_subtask_1.json\n",
            "Processing file 1s2Fz0wQD-YL0tR14PmgdYGuuI7pLarFS ubuntu_train_subtask_1.json\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YXsj5U-P1nj3ID2ni62vvW4m_4AMYh_v\n",
            "To: /content/Poly-Encoder/dstc7/ubuntu_dev_subtask_1.json\n",
            "100% 92.8M/92.8M [00:00<00:00, 374MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1I46tBMSYrDCFb0UoequBSl4Uqo0GOVms\n",
            "To: /content/Poly-Encoder/dstc7/ubuntu_responses_subtask_1.tsv\n",
            "100% 101k/101k [00:00<00:00, 107MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tHAe_WGFqQUHmdM28RttlVsYukL69qtg\n",
            "To: /content/Poly-Encoder/dstc7/ubuntu_test_subtask_1.json\n",
            "100% 18.4M/18.4M [00:00<00:00, 293MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s2Fz0wQD-YL0tR14PmgdYGuuI7pLarFS\n",
            "To: /content/Poly-Encoder/dstc7/ubuntu_train_subtask_1.json\n",
            "100% 1.86G/1.86G [00:06<00:00, 292MB/s]\n",
            "Download completed\n",
            "mv: cannot stat '/content/dstc7/*.json': No such file or directory\n",
            "mv: cannot stat '/content/dstc7/*.tsv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder/dstc7\n",
        "!bash parse.sh\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGQaVPejhcsG",
        "outputId": "854955ee-bc10-44c6-dcbc-64efca7c859f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder/dstc7\n",
            "tcmalloc: large alloc 1859141632 bytes == 0x28ba000 @  0x7f5383ec61e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x5939af 0x594cd3 0x594f8e 0x59526e 0x5bfba0 0x59aeca 0x515655 0x549e0e 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f5383ac3c87 0x5b621a\n",
            "tcmalloc: large alloc 1859141632 bytes == 0x715be000 @  0x7f5383ec61e7 0x4a3940 0x52ab72 0x527cf3 0x51d358 0x59358d 0x548c51 0x51566f 0x549576 0x4bcb19 0x59c019 0x59588e 0x595e64 0x4d8924 0x5bfbcb 0x59aeca 0x515655 0x549e0e 0x593fce 0x548ae9 0x51566f 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7f5383ac3c87 0x5b621a\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = 'klue/bert-base'"
      ],
      "metadata": {
        "id": "WheELxD_B2ly"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_config = BertConfig.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "yx0TP1yh2Q1Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "# tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "33cqB6o7_f3L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder"
      ],
      "metadata": {
        "id": "Hghi8P7p1qzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84d6614-b1f3-41be-bfd3-e14ae5307f11"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "def eval_running_model(dataloader, test=False):\n",
        "    model.eval()\n",
        "    eval_loss, eval_hit_times = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    r10 = r2 = r1 = r5 = 0\n",
        "    mrr = []\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        if args.architecture == 'cross':\n",
        "            text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch = batch\n",
        "            with torch.no_grad():\n",
        "                logits = model(text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch)\n",
        "                loss = F.cross_entropy(logits, torch.argmax(labels_batch, 1))\n",
        "        else:\n",
        "            context_token_ids_list_batch, context_input_masks_list_batch, \\\n",
        "            response_token_ids_list_batch, response_input_masks_list_batch, labels_batch = batch\n",
        "            with torch.no_grad():\n",
        "                logits = model(context_token_ids_list_batch, context_input_masks_list_batch,\n",
        "                                              response_token_ids_list_batch, response_input_masks_list_batch)\n",
        "                loss = F.cross_entropy(logits, torch.argmax(labels_batch, 1))\n",
        "        r2_indices = torch.topk(logits, 2)[1] # R 2 @ 100\n",
        "        r5_indices = torch.topk(logits, 5)[1] # R 5 @ 100\n",
        "        r10_indices = torch.topk(logits, 10)[1] # R 10 @ 100\n",
        "        r1 += (logits.argmax(-1) == 0).sum().item()\n",
        "        r2 += ((r2_indices==0).sum(-1)).sum().item()\n",
        "        r5 += ((r5_indices==0).sum(-1)).sum().item()\n",
        "        r10 += ((r10_indices==0).sum(-1)).sum().item()\n",
        "        # mrr\n",
        "        logits = logits.data.cpu().numpy()\n",
        "        for logit in logits:\n",
        "            y_true = np.zeros(len(logit))\n",
        "            y_true[0] = 1\n",
        "            mrr.append(label_ranking_average_precision_score([y_true], [logit]))\n",
        "        eval_loss += loss.item()\n",
        "        nb_eval_examples += labels_batch.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = r1 / nb_eval_examples\n",
        "    if not test:\n",
        "        result = {\n",
        "            'train_loss': tr_loss / nb_tr_steps,\n",
        "            'eval_loss': eval_loss,\n",
        "            'R1': r1 / nb_eval_examples,\n",
        "            'R2': r2 / nb_eval_examples,\n",
        "            'R5': r5 / nb_eval_examples,\n",
        "            'R10': r10 / nb_eval_examples,\n",
        "            'MRR': np.mean(mrr),\n",
        "            'epoch': epoch,\n",
        "            'global_step': global_step,\n",
        "        }\n",
        "    else:\n",
        "        result = {\n",
        "            'eval_loss': eval_loss,\n",
        "            'R1': r1 / nb_eval_examples,\n",
        "            'R2': r2 / nb_eval_examples,\n",
        "            'R5': r5 / nb_eval_examples,\n",
        "            'R10': r10 / nb_eval_examples,\n",
        "            'MRR': np.mean(mrr),\n",
        "        }\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "CtaB4Qhz4ps7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "        \"bert_model\": 'klue/bert-base',\n",
        "        \"eval\": False,\n",
        "        \"model_type\": 'bert',\n",
        "        \"output_dir\": 'output_dstc7/',\n",
        "        \"train_dir\": 'dstc7/',\n",
        "\n",
        "        \"use_pretrain\": True,\n",
        "        \"architecture\": 'poly',\n",
        "\n",
        "        \"max_contexts_length\": 128,\n",
        "        \"max_response_length\": 32,\n",
        "        \"train_batch_size\": 32,\n",
        "        \"eval_batch_size\": 32,\n",
        "        \"print_freq\": 100,\n",
        "\n",
        "        \"poly_m\": 16,\n",
        "\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_steps\": 100,\n",
        "        \"adam_epsilon\": 1e-8,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "\n",
        "        \"num_train_epochs\": 10.0,\n",
        "        'seed': 12345,\n",
        "        'gradient_accumulation_steps': 1,\n",
        "        \"fp16\": False,\n",
        "        \"fp16_opt_level\": \"O1\",\n",
        "        'gpu': 0\n",
        "        }"
      ],
      "metadata": {
        "id": "jKhi-3lB4tvY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict as edict\n",
        "args = edict(args)"
      ],
      "metadata": {
        "id": "CLTdqAqq7BZJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"%d\" % args.gpu\n",
        "set_seed(args)\n",
        "\n",
        "## init dataset and bert model\n",
        "model_name = 'klue/bert-base'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "context_transform = SelectionJoinTransform(tokenizer=tokenizer, max_len=args.max_contexts_length)\n",
        "response_transform = SelectionSequentialTransform(tokenizer=tokenizer, max_len=args.max_response_length)\n",
        "concat_transform = SelectionConcatTransform(tokenizer=tokenizer, max_len=args.max_response_length+args.max_contexts_length)\n",
        "\n",
        "print('=' * 80)\n",
        "print('Train dir:', args.train_dir)\n",
        "print('Output dir:', args.output_dir)\n",
        "print('=' * 80)\n",
        "\n",
        "if not args.eval:\n",
        "    train_dataset = SelectionDataset(os.path.join(args.train_dir, 'train.txt'),\n",
        "                                                                    context_transform, response_transform, concat_transform, sample_cnt=None, mode=args.architecture)\n",
        "    val_dataset = SelectionDataset(os.path.join(args.train_dir, 'dev.txt'),\n",
        "                                                                context_transform, response_transform, concat_transform, sample_cnt=1000, mode=args.architecture)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.train_batch_size, collate_fn=train_dataset.batchify_join_str, shuffle=True, num_workers=0)\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "else: # test\n",
        "    val_dataset = SelectionDataset(os.path.join(args.train_dir, 'test.txt'),\n",
        "                                                                context_transform, response_transform, concat_transform, sample_cnt=None, mode=args.architecture)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=args.eval_batch_size, collate_fn=val_dataset.batchify_join_str, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "epoch_start = 1\n",
        "global_step = 0\n",
        "best_eval_loss = float('inf')\n",
        "best_test_loss = float('inf')\n",
        "\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "\n",
        "log_wf = open(os.path.join(args.output_dir, 'log.txt'), 'a', encoding='utf-8')\n",
        "print(args, file=log_wf)\n",
        "\n",
        "state_save_path = os.path.join(args.output_dir, '{}_{}_pytorch_model.bin'.format(args.architecture, args.poly_m))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "########################################\n",
        "## build BERT encoder\n",
        "########################################\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "bert = BertModel.from_pretrained(model_name, config=bert_config)\n",
        "\n",
        "model = PolyEncoder(bert_config, bert=bert, poly_m=args.poly_m)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(device)\n",
        "\n",
        "if args.eval:\n",
        "    print('Loading parameters from', state_save_path)\n",
        "    model.load_state_dict(torch.load(state_save_path))\n",
        "    test_result = eval_running_model(val_dataloader, test=True)\n",
        "    print (test_result)\n",
        "    exit()\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": args.weight_decay,\n",
        "    },\n",
        "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        ")\n",
        "if args.fp16:\n",
        "    try:\n",
        "        from apex import amp\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "    model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "print_freq = args.print_freq//args.gradient_accumulation_steps\n",
        "eval_freq = min(len(train_dataloader) // 2, 1000)\n",
        "eval_freq = eval_freq//args.gradient_accumulation_steps\n",
        "print('Print freq:', print_freq, \"Eval freq:\", eval_freq)\n",
        "\n",
        "for epoch in range(epoch_start, int(args.num_train_epochs) + 1):\n",
        "    tr_loss = 0\n",
        "    nb_tr_steps = 0\n",
        "    with tqdm(total=len(train_dataloader)//args.gradient_accumulation_steps) as bar:\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            if args.architecture == 'cross':\n",
        "                text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch = batch\n",
        "                loss = model(text_token_ids_list_batch, text_input_masks_list_batch, text_segment_ids_list_batch, labels_batch)\n",
        "            else:\n",
        "                context_token_ids_list_batch, context_input_masks_list_batch, \\\n",
        "                response_token_ids_list_batch, response_input_masks_list_batch, labels_batch = batch\n",
        "                loss = model(context_token_ids_list_batch, context_input_masks_list_batch,\n",
        "                                        response_token_ids_list_batch, response_input_masks_list_batch,\n",
        "                                        labels_batch)\n",
        "\n",
        "            loss = loss / args.gradient_accumulation_steps\n",
        "            \n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "            \n",
        "            tr_loss += loss.item()\n",
        "\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                nb_tr_steps += 1\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if nb_tr_steps and nb_tr_steps % print_freq == 0:\n",
        "                    bar.update(min(print_freq, nb_tr_steps))\n",
        "                    time.sleep(0.02)\n",
        "                    print(global_step, tr_loss / nb_tr_steps)\n",
        "                    log_wf.write('%d\\t%f\\n' % (global_step, tr_loss / nb_tr_steps))\n",
        "\n",
        "                if global_step and global_step % eval_freq == 0:\n",
        "                    val_result = eval_running_model(val_dataloader)\n",
        "                    print('Global Step %d VAL res:\\n' % global_step, val_result)\n",
        "                    log_wf.write('Global Step %d VAL res:\\n' % global_step)\n",
        "                    log_wf.write(str(val_result) + '\\n')\n",
        "\n",
        "                    if val_result['eval_loss'] < best_eval_loss:\n",
        "                        best_eval_loss = val_result['eval_loss']\n",
        "                        val_result['best_eval_loss'] = best_eval_loss\n",
        "                        # save model\n",
        "                        print('[Saving at]', state_save_path)\n",
        "                        log_wf.write('[Saving at] %s\\n' % state_save_path)\n",
        "                        torch.save(model.state_dict(), state_save_path)\n",
        "            log_wf.flush()\n",
        "\n",
        "    # add a eval step after each epoch\n",
        "    val_result = eval_running_model(val_dataloader)\n",
        "    print('Epoch %d, Global Step %d VAL res:\\n' % (epoch, global_step), val_result)\n",
        "    log_wf.write('Global Step %d VAL res:\\n' % global_step)\n",
        "    log_wf.write(str(val_result) + '\\n')\n",
        "\n",
        "    if val_result['eval_loss'] < best_eval_loss:\n",
        "        best_eval_loss = val_result['eval_loss']\n",
        "        val_result['best_eval_loss'] = best_eval_loss\n",
        "        # save model\n",
        "        print('[Saving at]', state_save_path)\n",
        "        log_wf.write('[Saving at] %s\\n' % state_save_path)\n",
        "        torch.save(model.state_dict(), state_save_path)\n",
        "    print(global_step, tr_loss / nb_tr_steps)\n",
        "    log_wf.write('%d\\t%f\\n' % (global_step, tr_loss / nb_tr_steps))"
      ],
      "metadata": {
        "id": "jgSd5pJL4Swz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0ee1fd-4ac8-4158-c220-56a652ccbe2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Train dir: dstc7/\n",
            "Output dir: output_dstc7/\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print freq: 100 Eval freq: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 100/3125 [01:47<53:59,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 18.3373264169693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 200/3125 [03:35<52:39,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 12.122837131023408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses_input_ids = responses_input_ids.view(-1, seq_length)\n",
        "responses_input_masks = responses_input_masks.view(-1, seq_length)\n",
        "cand_emb = self.bert(responses_input_ids, responses_input_masks)[0][:,0,:] # [bs, dim]\n",
        "cand_emb = cand_emb.view(batch_size, res_cnt, -1) # [bs, res_cnt, dim]"
      ],
      "metadata": {
        "id": "lJXHTnWEhTKT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}