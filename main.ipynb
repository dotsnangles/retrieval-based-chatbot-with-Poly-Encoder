{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXPA7-uDAIHP"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "cade84d6-c463-4a52-8082-9e0fc8d701b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "e4b1e9ed-86bb-4fec-a07a-ad5d1367265d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  6 00:10:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-ZyBZPWfX5m",
        "outputId": "94804013-05db-4474-a687-cf79bec1285e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 56.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 57.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets folium==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "7aa669ee-0be8-4664-f399-98587d280a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 129 (delta 41), reused 20 (delta 8), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (129/129), 40.70 KiB | 1.07 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzRLhnM-stL",
        "outputId": "08f6a9db-b144-4fff-ea2c-7cdd81a76ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AcEZq-UQ-prG"
      },
      "outputs": [],
      "source": [
        "!gdown -q --folder 1Ipr-aNF5ELMY0HTXAmeV26LlgktKUfmG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psjYArLBO1-C"
      },
      "outputs": [],
      "source": [
        "# \"--bert_model\", default='ckpt/pretrained/bert-small-uncased', type=str\n",
        "# \"--eval\", action=\"store_true\"\n",
        "# \"--model_type\", default='bert', type=str\n",
        "# \"--output_dir\", required=True, type=str\n",
        "# \"--train_dir\", default='data/ubuntu_data', type=str\n",
        "# \"--train_file\", default='data/ubuntu_data', type=str\n",
        "# \"--dev_file\", default='data/ubuntu_data', type=str\n",
        "# \"--test_file\", default='data/ubuntu_data', type=str\n",
        "\n",
        "# \"--use_pretrain\", action=\"store_true\"\n",
        "# \"--architecture\", required=True, type=str, help='[poly, bi, cross]'\n",
        "\n",
        "# \"--max_contexts_length\", default=128, type=int\n",
        "# \"--max_response_length\", default=32, type=int\n",
        "# \"--train_batch_size\", default=32, type=int, help=\"Total batch size for training.\"\n",
        "# \"--eval_batch_size\", default=32, type=int, help=\"Total batch size for eval.\"\n",
        "# \"--print_freq\", default=100, type=int, help=\"Log frequency\"\n",
        "\n",
        "# \"--poly_m\", default=0, type=int, help=\"Number of m of polyencoder\"\n",
        "\n",
        "# \"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\"\n",
        "# \"--weight_decay\", default=0.01, type=float\n",
        "# \"--warmup_steps\", default=100, type=float\n",
        "# \"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\"\n",
        "# \"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\"\n",
        "\n",
        "# \"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        "# '--seed', type=int, default=12345, help=\"random seed for initialization\"\n",
        "# '--gradient_accumulation_steps', type=int, default=1, help=\"Number of updates steps to accumulate before performing a backward/update pass.\"\n",
        "\n",
        "# \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"\n",
        "\n",
        "# \"--fp16_opt_level\", type=str, default=\"O1\", help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\" \"See details at https://nvidia.github.io/apex/amp.html\"\n",
        "# '--gpu', type=int, default=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 run.py \\\n",
        "# \\\n",
        "# --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' \\\n",
        "# --train_dir '감성대화챗봇데이터/' \\\n",
        "# --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' \\\n",
        "# --architecture poly --poly_m 16 \\\n",
        "# \\\n",
        "# --num_train_epochs 10 \\\n",
        "# \\\n",
        "# --train_batch_size 4 \\\n",
        "# --eval_batch_size 4 \\\n",
        "# --gradient_accumulation_steps 1 \\\n",
        "# \\\n",
        "# --print_freq 800 \\ \n",
        "# \\\n",
        "# --max_contexts_length 256 --max_response_length 128"
      ],
      "metadata": {
        "id": "mqEuPskv5T1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch5QnDV6jVZj",
        "outputId": "d1e6ce58-2a44-4376-da86-858391e37c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(adam_epsilon=1e-08, architecture='poly', bert_model='klue/bert-base', dev_file='val_data_source.pickle', eval=False, eval_batch_size=4, fp16=False, fp16_opt_level='O1', gpu=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_contexts_length=256, max_grad_norm=1.0, max_response_length=128, model_type='bert', num_train_epochs=10.0, output_dir='chatbot_output/', poly_m=16, print_freq=800, seed=12345, test_file='test_data_source.pickle', train_batch_size=4, train_dir='감성대화챗봇데이터/', train_file='train_data_source.pickle', use_pretrain=False, warmup_steps=100, weight_decay=0.01)\n",
            "Downloading: 100% 243k/243k [00:00<00:00, 344kB/s]\n",
            "Downloading: 100% 125/125 [00:00<00:00, 107kB/s]\n",
            "Downloading: 100% 289/289 [00:00<00:00, 211kB/s]\n",
            "Downloading: 100% 425/425 [00:00<00:00, 340kB/s]\n",
            "================================================================================\n",
            "Train dir: 감성대화챗봇데이터/\n",
            "Output dir: chatbot_output/\n",
            "================================================================================\n",
            "Downloading: 100% 424M/424M [00:08<00:00, 50.9MB/s]\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Print freq: 800 Eval freq: 1000\n",
            "  8% 800/10220 [02:50<33:26,  4.69it/s]800 4.049495717436075\n",
            "Global Step 1000 VAL res:\n",
            " {'train_loss': 3.7431009992957116, 'eval_loss': 2.7083300349309125, 'R1': 0.06530214424951267, 'R2': 0.1304093567251462, 'R5': 0.33001949317738793, 'R10': 0.6647173489278753, 'MRR': 0.21863490364952354, 'epoch': 1, 'global_step': 1000}\n",
            "[Saving at] chatbot_output/poly_16_pytorch_model.bin\n",
            " 16% 1600/10220 [11:26<1:07:04,  2.14it/s]1600 3.222172443009913\n",
            "Global Step 2000 VAL res:\n",
            " {'train_loss': 3.7926917487382887, 'eval_loss': 2.7080801321209544, 'R1': 0.06549707602339182, 'R2': 0.13528265107212475, 'R5': 0.3309941520467836, 'R10': 0.6729044834307992, 'MRR': 0.21599229230808178, 'epoch': 1, 'global_step': 2000}\n",
            "[Saving at] chatbot_output/poly_16_pytorch_model.bin\n",
            " 23% 2400/10220 [20:01<1:11:25,  1.82it/s]2400 3.560323608741164\n",
            "Global Step 3000 VAL res:\n",
            " {'train_loss': 3.27356016266346, 'eval_loss': 2.7080466578179565, 'R1': 0.1189083820662768, 'R2': 0.21968810916179338, 'R5': 0.46530214424951266, 'R10': 0.7697855750487329, 'MRR': 0.178743689708602, 'epoch': 1, 'global_step': 3000}\n",
            "[Saving at] chatbot_output/poly_16_pytorch_model.bin\n",
            " 31% 3200/10220 [28:39<1:08:41,  1.70it/s]3200 3.2008105143532157\n",
            " 39% 4000/10220 [31:30<46:54,  2.21it/s]  4000 2.966103941857815\n",
            "Global Step 4000 VAL res:\n",
            " {'train_loss': 2.966103941857815, 'eval_loss': 2.708050703686471, 'R1': 0.20019493177387915, 'R2': 0.347953216374269, 'R5': 0.6385964912280702, 'R10': 0.8444444444444444, 'MRR': 0.13965666021221576, 'epoch': 1, 'global_step': 4000}\n",
            " 47% 4800/10220 [40:03<46:41,  1.93it/s]4800 2.8030033900340396\n",
            "Global Step 5000 VAL res:\n",
            " {'train_loss': 2.7681656705617903, 'eval_loss': 2.708051021454024, 'R1': 0.19980506822612085, 'R2': 0.32046783625730996, 'R5': 0.7085769980506823, 'R10': 0.9559454191033139, 'MRR': 0.1299791598914406, 'epoch': 1, 'global_step': 5000}\n",
            " 55% 5600/10220 [48:36<42:55,  1.79it/s]5600 2.670639400673764\n",
            "Global Step 6000 VAL res:\n",
            " {'train_loss': 2.6166902893980346, 'eval_loss': 2.708051354273724, 'R1': 0.4202729044834308, 'R2': 0.4368421052631579, 'R5': 0.5138401559454191, 'R10': 0.8245614035087719, 'MRR': 0.11200309328964299, 'epoch': 1, 'global_step': 6000}\n",
            " 63% 6400/10220 [57:09<37:11,  1.71it/s]6400 2.569318229723722\n",
            "Global Step 7000 VAL res:\n",
            " {'train_loss': 2.505217439361981, 'eval_loss': 2.708050936901839, 'R1': 0.47387914230019496, 'R2': 0.5530214424951267, 'R5': 0.6405458089668616, 'R10': 0.8643274853801169, 'MRR': 0.1024115212273107, 'epoch': 1, 'global_step': 7000}\n",
            " 70% 7200/10220 [1:05:43<30:18,  1.66it/s]7200 2.4857180692586636\n",
            " 78% 8000/10220 [1:08:33<17:50,  2.07it/s]8000 2.4129099413156507\n",
            "Global Step 8000 VAL res:\n",
            " {'train_loss': 2.4129099413156507, 'eval_loss': 2.708050592374913, 'R1': 0.582261208576998, 'R2': 0.7475633528265108, 'R5': 0.847953216374269, 'R10': 0.8812865497076023, 'MRR': 0.09402740209757753, 'epoch': 1, 'global_step': 8000}\n",
            " 86% 8800/10220 [1:17:06<12:33,  1.88it/s]8800 2.349945345439694\n",
            "Global Step 9000 VAL res:\n",
            " {'train_loss': 2.3358965705302026, 'eval_loss': 2.708051248537035, 'R1': 0.5799220272904484, 'R2': 0.6814814814814815, 'R5': 0.708187134502924, 'R10': 0.8428849902534113, 'MRR': 0.09478105011730742, 'epoch': 1, 'global_step': 9000}\n",
            " 94% 9600/10220 [1:25:38<05:49,  1.77it/s]9600 2.296616247886171\n",
            "Global Step 10000 VAL res:\n",
            " {'train_loss': 2.2734179356753828, 'eval_loss': 2.708051192974171, 'R1': 0.5348927875243664, 'R2': 0.5475633528265107, 'R5': 0.5719298245614035, 'R10': 0.798635477582846, 'MRR': 0.10083565827717875, 'epoch': 1, 'global_step': 10000}\n",
            " 94% 9600/10220 [1:33:32<06:02,  1.71it/s]\n",
            "Epoch 1, Global Step 10220 VAL res:\n",
            " {'train_loss': 2.2608467116922784, 'eval_loss': 2.708050062019009, 'R1': 0.23157894736842105, 'R2': 0.28771929824561404, 'R5': 0.5444444444444444, 'R10': 0.9350877192982456, 'MRR': 0.13612121525864215, 'epoch': 1, 'global_step': 10220}\n",
            "10220 2.2608467116922784\n",
            "  0% 0/10220 [00:00<?, ?it/s]Global Step 11000 VAL res:\n",
            " {'train_loss': 1.6858033155019467, 'eval_loss': 2.708050284642125, 'R1': 0.34171539961013647, 'R2': 0.3925925925925926, 'R5': 0.5994152046783626, 'R10': 0.856140350877193, 'MRR': 0.11727700824192051, 'epoch': 2, 'global_step': 11000}\n",
            "  8% 800/10220 [08:31<1:40:24,  1.56it/s]11020 1.686110351756215\n",
            " 16% 1600/10220 [11:21<55:46,  2.58it/s] 11820 1.6795260835811496\n",
            "Global Step 12000 VAL res:\n",
            " {'train_loss': 1.6788318943776441, 'eval_loss': 2.708049910196734, 'R1': 0.42904483430799223, 'R2': 0.45730994152046783, 'R5': 0.6456140350877193, 'R10': 0.9284600389863548, 'MRR': 0.10617577300325838, 'epoch': 2, 'global_step': 12000}\n",
            " 23% 2400/10220 [19:53<1:05:34,  1.99it/s]12620 1.6694398663689693\n",
            "Global Step 13000 VAL res:\n",
            " {'train_loss': 1.6652785981087377, 'eval_loss': 2.708048936638717, 'R1': 0.6247563352826511, 'R2': 0.6272904483430799, 'R5': 0.6604288499025341, 'R10': 0.8387914230019493, 'MRR': 0.09607698398634072, 'epoch': 2, 'global_step': 13000}\n",
            " 31% 3200/10220 [28:25<1:05:10,  1.80it/s]13420 1.6606598992459476\n",
            "Global Step 14000 VAL res:\n",
            " {'train_loss': 1.6548040807404847, 'eval_loss': 2.7080498133798363, 'R1': 0.5058479532163743, 'R2': 0.5692007797270955, 'R5': 0.6409356725146199, 'R10': 0.8329434697855751, 'MRR': 0.10500042625773619, 'epoch': 2, 'global_step': 14000}\n",
            " 39% 4000/10220 [36:58<1:00:53,  1.70it/s]14220 1.6535291326791048\n",
            "Global Step 15000 VAL res:\n",
            " {'train_loss': 1.6477646654744527, 'eval_loss': 2.7080490934783747, 'R1': 0.33606237816764134, 'R2': 0.356140350877193, 'R5': 0.52046783625731, 'R10': 0.8898635477582846, 'MRR': 0.1250523085318407, 'epoch': 2, 'global_step': 15000}\n",
            " 47% 4800/10220 [45:31<54:44,  1.65it/s]  15020 1.647432014433046\n",
            " 55% 5600/10220 [48:22<36:47,  2.09it/s]15820 1.6424587569385767\n",
            "Global Step 16000 VAL res:\n",
            " {'train_loss': 1.6414270285607209, 'eval_loss': 2.7080507761597725, 'R1': 0.25555555555555554, 'R2': 0.3730994152046784, 'R5': 0.7175438596491228, 'R10': 0.9444444444444444, 'MRR': 0.12002613208753558, 'epoch': 2, 'global_step': 16000}\n",
            " 63% 6400/10220 [56:55<33:42,  1.89it/s]16620 1.638787359641865\n",
            "Global Step 17000 VAL res:\n",
            " {'train_loss': 1.635759535185707, 'eval_loss': 2.708049763949328, 'R1': 0.21267056530214426, 'R2': 0.4064327485380117, 'R5': 0.8360623781676413, 'R10': 0.99317738791423, 'MRR': 0.1338531340870522, 'epoch': 2, 'global_step': 17000}\n",
            " 70% 7200/10220 [1:05:26<28:22,  1.77it/s]17420 1.6323464313728941\n",
            "Global Step 18000 VAL res:\n",
            " {'train_loss': 1.629326381007626, 'eval_loss': 2.7080498256445487, 'R1': 0.3961013645224172, 'R2': 0.5370370370370371, 'R5': 0.68635477582846, 'R10': 0.9003898635477583, 'MRR': 0.11454431317004415, 'epoch': 2, 'global_step': 18000}\n",
            " 78% 8000/10220 [1:13:57<21:43,  1.70it/s]18220 1.6279631299600006\n",
            "Global Step 19000 VAL res:\n",
            " {'train_loss': 1.6229237851154288, 'eval_loss': 2.708049644832953, 'R1': 0.2777777777777778, 'R2': 0.47680311890838206, 'R5': 0.8695906432748538, 'R10': 0.9633528265107213, 'MRR': 0.12834037632283246, 'epoch': 2, 'global_step': 19000}\n",
            " 86% 8800/10220 [1:22:28<14:16,  1.66it/s]19020 1.6227283618599175\n",
            " 94% 9600/10220 [1:25:18<05:00,  2.07it/s]19820 1.61822523597007\n",
            "Global Step 20000 VAL res:\n",
            " {'train_loss': 1.6170036532213352, 'eval_loss': 2.708050308985721, 'R1': 0.4988304093567251, 'R2': 0.6797270955165692, 'R5': 0.8440545808966862, 'R10': 0.8925925925925926, 'MRR': 0.10365721564551972, 'epoch': 2, 'global_step': 20000}\n",
            " 94% 9600/10220 [1:33:11<06:01,  1.72it/s]\n",
            "Epoch 2, Global Step 20440 VAL res:\n",
            " {'train_loss': 1.614293131920456, 'eval_loss': 2.708049594659129, 'R1': 0.8306042884990253, 'R2': 0.8481481481481481, 'R5': 0.8500974658869396, 'R10': 0.8873294346978557, 'MRR': 0.07954803318838406, 'epoch': 2, 'global_step': 20440}\n",
            "20440 1.614293131920456\n",
            "  0% 0/10220 [00:00<?, ?it/s]Global Step 21000 VAL res:\n",
            " {'train_loss': 1.5426763377019337, 'eval_loss': 2.708050577694424, 'R1': 0.7444444444444445, 'R2': 0.7758284600389863, 'R5': 0.7953216374269005, 'R10': 0.8329434697855751, 'MRR': 0.08450347735435455, 'epoch': 3, 'global_step': 21000}\n",
            "  8% 800/10220 [08:31<1:40:27,  1.56it/s]21240 1.5466799134016036\n",
            "Global Step 22000 VAL res:\n",
            " {'train_loss': 1.5491066426038742, 'eval_loss': 2.7080498964453894, 'R1': 0.1746588693957115, 'R2': 0.3101364522417154, 'R5': 0.7407407407407407, 'R10': 0.9900584795321637, 'MRR': 0.14072804064032135, 'epoch': 3, 'global_step': 22000}\n",
            " 16% 1600/10220 [17:03<1:31:53,  1.56it/s]22040 1.5485041815787555\n",
            " 23% 2400/10220 [19:53<57:58,  2.25it/s]  22840 1.5431218401590983\n",
            "Global Step 23000 VAL res:\n",
            " {'train_loss': 1.5435907367616892, 'eval_loss': 2.7080506616891222, 'R1': 0.8021442495126706, 'R2': 0.8773879142300195, 'R5': 0.8844054580896686, 'R10': 0.8920077972709551, 'MRR': 0.07929003095669762, 'epoch': 3, 'global_step': 23000}\n",
            " 31% 3200/10220 [28:24<1:00:58,  1.92it/s]23640 1.5414600498601794\n",
            "Global Step 24000 VAL res:\n",
            " {'train_loss': 1.5393746289644348, 'eval_loss': 2.70804996910452, 'R1': 0.1695906432748538, 'R2': 0.42007797270955166, 'R5': 0.8742690058479532, 'R10': 0.9216374269005848, 'MRR': 0.14605798684746052, 'epoch': 3, 'global_step': 24000}\n",
            " 39% 4000/10220 [36:55<58:26,  1.77it/s]  24440 1.5376297743916512\n",
            "Global Step 25000 VAL res:\n",
            " {'train_loss': 1.5357420444488525, 'eval_loss': 2.7080505977639535, 'R1': 0.346588693957115, 'R2': 0.5886939571150097, 'R5': 0.849317738791423, 'R10': 0.9062378167641325, 'MRR': 0.11606640111026074, 'epoch': 3, 'global_step': 25000}\n",
            " 47% 4800/10220 [45:27<53:14,  1.70it/s]25240 1.5344946888585886\n",
            "Global Step 26000 VAL res:\n",
            " {'train_loss': 1.531803649578163, 'eval_loss': 2.708037707922706, 'R1': 0.08732943469785576, 'R2': 0.19161793372319688, 'R5': 0.47426900584795323, 'R10': 0.79317738791423, 'MRR': 0.19177846087202813, 'epoch': 3, 'global_step': 26000}\n",
            "[Saving at] chatbot_output/poly_16_pytorch_model.bin\n",
            " 55% 5600/10220 [53:59<46:39,  1.65it/s]26040 1.5318826566849435\n",
            " 63% 6400/10220 [56:49<30:36,  2.08it/s]26840 1.5294688711501658\n",
            "Global Step 27000 VAL res:\n",
            " {'train_loss': 1.5287985440797922, 'eval_loss': 2.7080500321005436, 'R1': 0.2851851851851852, 'R2': 0.454775828460039, 'R5': 0.6011695906432749, 'R10': 0.9183235867446394, 'MRR': 0.12552671716414407, 'epoch': 3, 'global_step': 27000}\n",
            " 70% 7200/10220 [1:05:20<26:40,  1.89it/s]27640 1.5265275101860365\n",
            "Global Step 28000 VAL res:\n",
            " {'train_loss': 1.5252231332202437, 'eval_loss': 2.7080506564859106, 'R1': 0.3783625730994152, 'R2': 0.453411306042885, 'R5': 0.5627680311890838, 'R10': 0.8267056530214425, 'MRR': 0.11765671895788854, 'epoch': 3, 'global_step': 28000}\n",
            " 78% 8000/10220 [1:13:51<20:51,  1.77it/s]28440 1.5235213821679354\n",
            "Global Step 29000 VAL res:\n",
            " {'train_loss': 1.5211345206632791, 'eval_loss': 2.7080504368360585, 'R1': 0.40623781676413256, 'R2': 0.5368421052631579, 'R5': 0.6448343079922028, 'R10': 0.9035087719298246, 'MRR': 0.1078124853271052, 'epoch': 3, 'global_step': 29000}\n",
            " 86% 8800/10220 [1:22:21<13:52,  1.71it/s]29240 1.5203476936302402\n",
            "Global Step 30000 VAL res:\n",
            " {'train_loss': 1.5182607289263395, 'eval_loss': 2.70804969444929, 'R1': 0.16296296296296298, 'R2': 0.265692007797271, 'R5': 0.5549707602339181, 'R10': 0.8978557504873295, 'MRR': 0.15590963292717677, 'epoch': 3, 'global_step': 30000}\n",
            " 94% 9600/10220 [1:30:51<06:13,  1.66it/s]30040 1.518047677911818\n",
            " 94% 9600/10220 [1:33:01<06:00,  1.72it/s]\n",
            "Epoch 3, Global Step 30660 VAL res:\n",
            " {'train_loss': 1.5160562156231203, 'eval_loss': 2.7080498059466773, 'R1': 0.20662768031189083, 'R2': 0.3713450292397661, 'R5': 0.7690058479532164, 'R10': 0.9766081871345029, 'MRR': 0.1377003427588223, 'epoch': 3, 'global_step': 30660}\n",
            "30660 1.5160562156231203\n",
            "  0% 0/10220 [00:00<?, ?it/s]Global Step 31000 VAL res:\n",
            " {'train_loss': 1.4885738477987402, 'eval_loss': 2.7080500438077695, 'R1': 0.35906432748538014, 'R2': 0.44853801169590646, 'R5': 0.6504873294346979, 'R10': 0.9481481481481482, 'MRR': 0.11585404037158423, 'epoch': 4, 'global_step': 31000}\n",
            "  8% 800/10220 [08:29<1:40:01,  1.57it/s]31460 1.481254422366619\n",
            "Global Step 32000 VAL res:\n",
            " {'train_loss': 1.478511065422599, 'eval_loss': 2.708049570315533, 'R1': 0.42787524366471735, 'R2': 0.6076023391812866, 'R5': 0.8855750487329435, 'R10': 0.9730994152046784, 'MRR': 0.11128171752440758, 'epoch': 4, 'global_step': 32000}\n",
            " 16% 1600/10220 [17:01<1:31:42,  1.57it/s]32260 1.477552016377449\n",
            "Global Step 33000 VAL res:\n",
            " {'train_loss': 1.4771435484926925, 'eval_loss': 2.708050475302657, 'R1': 0.2651072124756335, 'R2': 0.34580896686159845, 'R5': 0.6210526315789474, 'R10': 0.9208576998050683, 'MRR': 0.12475134839169927, 'epoch': 4, 'global_step': 33000}\n",
            " 23% 2400/10220 [25:32<1:23:16,  1.57it/s]33060 1.4773685056467851\n",
            " 31% 3200/10220 [28:22<55:03,  2.12it/s]  33860 1.4750903572887182\n",
            "Global Step 34000 VAL res:\n",
            " {'train_loss': 1.4748004388309524, 'eval_loss': 2.7080508395274543, 'R1': 0.353411306042885, 'R2': 0.6350877192982456, 'R5': 0.9594541910331384, 'R10': 0.9994152046783625, 'MRR': 0.10853702719199793, 'epoch': 4, 'global_step': 34000}\n",
            " 39% 4000/10220 [36:54<55:05,  1.88it/s]34660 1.4738861583173275\n",
            "Global Step 35000 VAL res:\n",
            " {'train_loss': 1.473091976900804, 'eval_loss': 2.708050277394795, 'R1': 0.4818713450292398, 'R2': 0.7134502923976608, 'R5': 0.9543859649122807, 'R10': 0.9996101364522417, 'MRR': 0.10080857738752474, 'epoch': 4, 'global_step': 35000}\n",
            " 47% 4800/10220 [45:25<51:17,  1.76it/s]35460 1.4721223461131254\n",
            "Global Step 36000 VAL res:\n",
            " {'train_loss': 1.4708966467710916, 'eval_loss': 2.7080504438975597, 'R1': 0.34327485380116957, 'R2': 0.3865497076023392, 'R5': 0.6674463937621833, 'R10': 0.9270955165692008, 'MRR': 0.11142497420275196, 'epoch': 4, 'global_step': 36000}\n",
            " 55% 5600/10220 [53:55<45:30,  1.69it/s]36260 1.4702926060557366\n",
            "Global Step 37000 VAL res:\n",
            " {'train_loss': 1.468617971274379, 'eval_loss': 2.7080501588359067, 'R1': 0.7974658869395711, 'R2': 0.9580896686159844, 'R5': 0.9970760233918129, 'R10': 0.9978557504873294, 'MRR': 0.08112150033202663, 'epoch': 4, 'global_step': 37000}\n",
            " 63% 6400/10220 [1:02:28<38:37,  1.65it/s]37060 1.4684996739961207\n",
            " 70% 7200/10220 [1:05:17<24:19,  2.07it/s]37860 1.4669754379656579\n",
            "Global Step 38000 VAL res:\n",
            " {'train_loss': 1.4667715474272944, 'eval_loss': 2.7080504308895312, 'R1': 0.6539961013645225, 'R2': 0.6578947368421053, 'R5': 0.68635477582846, 'R10': 0.8298245614035088, 'MRR': 0.09237830125257025, 'epoch': 4, 'global_step': 38000}\n",
            " 78% 8000/10220 [1:13:48<19:39,  1.88it/s]38660 1.465470003426075\n",
            "Global Step 39000 VAL res:\n",
            " {'train_loss': 1.4648797156713564, 'eval_loss': 2.7080498631820022, 'R1': 0.37290448343079924, 'R2': 0.5625730994152047, 'R5': 0.8875243664717349, 'R10': 0.9951267056530214, 'MRR': 0.1113664016295595, 'epoch': 4, 'global_step': 39000}\n",
            " 86% 8800/10220 [1:22:20<13:21,  1.77it/s]39460 1.464287714646621\n",
            "Global Step 40000 VAL res:\n",
            " {'train_loss': 1.4633538854198742, 'eval_loss': 2.7080503833173126, 'R1': 0.6434697855750487, 'R2': 0.850682261208577, 'R5': 0.9629629629629629, 'R10': 0.9725146198830409, 'MRR': 0.08986303224607319, 'epoch': 4, 'global_step': 40000}\n",
            " 94% 9600/10220 [1:30:51<06:03,  1.70it/s]40260 1.4628783756121992\n",
            " 94% 9600/10220 [1:33:03<06:00,  1.72it/s]\n",
            "Epoch 4, Global Step 40880 VAL res:\n",
            " {'train_loss': 1.4619768638900115, 'eval_loss': 2.70805010550299, 'R1': 0.7955165692007797, 'R2': 0.7955165692007797, 'R5': 0.7990253411306043, 'R10': 0.8592592592592593, 'MRR': 0.0808849088966048, 'epoch': 4, 'global_step': 40880}\n",
            "40880 1.4619768638900115\n",
            "  0% 0/10220 [00:00<?, ?it/s]Global Step 41000 VAL res:\n",
            " {'train_loss': 1.4344559510548909, 'eval_loss': 2.708049935841133, 'R1': 0.3202729044834308, 'R2': 0.5976608187134503, 'R5': 0.9578947368421052, 'R10': 0.9775828460038987, 'MRR': 0.12097304471573478, 'epoch': 5, 'global_step': 41000}\n",
            "  8% 800/10220 [08:32<1:40:37,  1.56it/s]41680 1.4465791630744933\n",
            "Global Step 42000 VAL res:\n",
            " {'train_loss': 1.4451390120599952, 'eval_loss': 2.7080509644045274, 'R1': 0.5927875243664718, 'R2': 0.5935672514619883, 'R5': 0.6124756335282651, 'R10': 0.7883040935672515, 'MRR': 0.0962761485860901, 'epoch': 5, 'global_step': 42000}\n",
            " 16% 1600/10220 [17:06<1:32:10,  1.56it/s]42480 1.4439047749340534\n"
          ]
        }
      ],
      "source": [
        "!python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --num_train_epochs 10 --train_batch_size 4 --eval_batch_size 4 --gradient_accumulation_steps 1 --print_freq 200 --max_contexts_length 256 --max_response_length 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POq7e5BjjXSr"
      },
      "outputs": [],
      "source": [
        "# !python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Qdur4wRAhb"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/Poly-Encoder/output_dstc7 '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--6Br9QFwy3N"
      },
      "outputs": [],
      "source": [
        "# PATH = '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder/output_dstc7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRR5o3kNRMLw",
        "outputId": "e9e1dfe8-ff6e-44ec-c8aa-ae2b0ec6b041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWnJ129TxQSl",
        "outputId": "508720fc-d438-4be6-e6de-f61cedb5b127"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(32001, 768)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertPreTrainedModel, BertConfig, BertModel, BertTokenizer, AutoModel\n",
        "from encoder import PolyEncoder\n",
        "from transform import SelectionJoinTransform, SelectionSequentialTransform\n",
        "\n",
        "PATH = '/content/Poly-Encoder/chatbot_output/poly_16_pytorch_model.bin'\n",
        "\n",
        "bert_name = 'klue/bert-base'\n",
        "bert_config = BertConfig.from_pretrained(bert_name)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
        "tokenizer.add_tokens(['\\n'], special_tokens=True)\n",
        "\n",
        "context_transform = SelectionJoinTransform(tokenizer=tokenizer, max_len=256)\n",
        "response_transform = SelectionSequentialTransform(tokenizer=tokenizer, max_len=128)\n",
        "\n",
        "bert = BertModel.from_pretrained(bert_name, config=bert_config)\n",
        "\n",
        "model = PolyEncoder(bert_config, bert=bert, poly_m=16)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "# model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rapB1afogMhI"
      },
      "outputs": [],
      "source": [
        "context = ['This framework generates embeddings for each input sentence', \n",
        "           'Sentences are passed as a list of string.', \n",
        "           'The quick brown fox jumps over the lazy dog.']\n",
        "\n",
        "candidates = ['This framework generates embeddings for each input sentence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FAPphUhb-jp"
      },
      "outputs": [],
      "source": [
        "context_input_ids, context_input_masks = context_transform(context)\n",
        "responses_token_ids_list, responses_input_masks_list = response_transform(candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9CP9rzow1ec"
      },
      "outputs": [],
      "source": [
        "contexts_token_ids_list_batch, contexts_input_masks_list_batch, \\\n",
        "responses_token_ids_list_batch, responses_input_masks_list_batch = [context_input_ids], [context_input_masks], [responses_token_ids_list], [responses_input_masks_list]\n",
        "\n",
        "long_tensors = [contexts_token_ids_list_batch, contexts_input_masks_list_batch,\n",
        "                                            responses_token_ids_list_batch, responses_input_masks_list_batch]\n",
        "\n",
        "contexts_token_ids_list_batch, contexts_input_masks_list_batch, \\\n",
        "responses_token_ids_list_batch, responses_input_masks_list_batch = (torch.tensor(t, dtype=torch.long) for t in long_tensors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward\n",
        "model(contexts_token_ids_list_batch, contexts_input_masks_list_batch, responses_token_ids_list_batch, responses_input_masks_list_batch)"
      ],
      "metadata": {
        "id": "IwPAL7K4ymBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_ELL57RV6vb"
      },
      "outputs": [],
      "source": [
        "def embs_gen(contexts_token_ids_list_batch, contexts_input_masks_list_batch):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        \n",
        "        ctx_out = model.bert(contexts_token_ids_list_batch, contexts_input_masks_list_batch)[0]  # [bs, length, dim]\n",
        "        poly_code_ids = torch.arange(model.poly_m, dtype=torch.long).to(contexts_token_ids_list_batch.device)\n",
        "        poly_code_ids = poly_code_ids.unsqueeze(0).expand(1, model.poly_m)\n",
        "        poly_codes = model.poly_code_embeddings(poly_code_ids) # [bs, poly_m, dim]\n",
        "        embs = model.dot_attention(poly_codes, ctx_out, ctx_out) # [bs, poly_m, dim]\n",
        "\n",
        "        return embs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embs = embs_gen(contexts_token_ids_list_batch, contexts_input_masks_list_batch)"
      ],
      "metadata": {
        "id": "IG58NhFdYW8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cand_emb_gen(responses_token_ids_list_batch, responses_input_masks_list_batch):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "                \n",
        "        batch_size, res_cnt, seq_length = responses_token_ids_list_batch.shape # res_cnt is 1 during training\n",
        "        responses_token_ids_list_batch = responses_token_ids_list_batch.view(-1, seq_length)\n",
        "        responses_input_masks_list_batch = responses_input_masks_list_batch.view(-1, seq_length)\n",
        "        cand_emb = model.bert(responses_token_ids_list_batch, responses_input_masks_list_batch)[0][:,0,:] # [bs, dim]\n",
        "        cand_emb = cand_emb.view(batch_size, res_cnt, -1) # [bs, res_cnt, dim]\n",
        "\n",
        "        return cand_emb"
      ],
      "metadata": {
        "id": "vwA8KNRm9_K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cand_emb = cand_emb_gen(responses_token_ids_list_batch, responses_input_masks_list_batch)"
      ],
      "metadata": {
        "id": "TWCWgALsYZN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(embs, cand_emb):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        ctx_emb = model.dot_attention(cand_emb, embs, embs) # [bs, res_cnt, dim]\n",
        "        dot_product = (ctx_emb*cand_emb).sum(-1)\n",
        "        \n",
        "        return dot_product"
      ],
      "metadata": {
        "id": "B47Tw6vTKYr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score(embs, cand_emb)"
      ],
      "metadata": {
        "id": "JnKdzX6JYifc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7AEttyhXCLF",
        "outputId": "74bf8fe1-1205-42de-fe9d-a5b76aba46cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 768])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QogL8-GqSwMs"
      },
      "outputs": [],
      "source": [
        "model.dot_attention()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaZTYkCwXRzK"
      },
      "source": [
        "### BK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wtBKHLEQB_u"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    model_output = model.bert(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdwrcO10Sm9i",
        "outputId": "911c2624-c892-47a7-e0ec-d39f9ff1c829"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 25, 768])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_output[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBSSzmh7eT62",
        "outputId": "d26efd1a-3022-49ea-c106-12cd0a48e0f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.3614, -0.0401,  0.1556,  ...,  0.0636, -0.2290,  0.3956],\n",
              "        [ 0.3748, -0.0499,  0.1429,  ...,  0.0620, -0.2202,  0.3896],\n",
              "        [ 0.3673, -0.0366,  0.1440,  ...,  0.0596, -0.2208,  0.3850]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_output[0][:,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyYKB0CeiyYb"
      },
      "outputs": [],
      "source": [
        "model_output = model.bert(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrntQcELizgh",
        "outputId": "9b37a039-c29c-479c-f409-d84ef51df41e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0931, -0.1231, -0.0292,  ..., -0.0014, -0.1432,  0.1350],\n",
              "        [ 0.0868, -0.1291, -0.0281,  ..., -0.0047, -0.1368,  0.1317],\n",
              "        [ 0.0876, -0.1231, -0.0293,  ..., -0.0074, -0.1360,  0.1305]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_output[0][:,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts_token_ids_list_batch, contexts_input_masks_list_batch, \\\n",
        "responses_token_ids_list_batch, responses_input_masks_list_batch = [], [], [], []\n",
        "labels_batch = []\n",
        "for sample in batch:\n",
        "    (contexts_token_ids_list, contexts_input_masks_list), (responses_token_ids_list, responses_input_masks_list) = sample[:2]\n",
        "\n",
        "    contexts_token_ids_list_batch.append(contexts_token_ids_list)\n",
        "    contexts_input_masks_list_batch.append(contexts_input_masks_list)\n",
        "\n",
        "    responses_token_ids_list_batch.append(responses_token_ids_list)\n",
        "    responses_input_masks_list_batch.append(responses_input_masks_list)\n",
        "\n",
        "    labels_batch.append(sample[-1])\n",
        "\n",
        "long_tensors = [contexts_token_ids_list_batch, contexts_input_masks_list_batch,\n",
        "                                responses_token_ids_list_batch, responses_input_masks_list_batch]\n",
        "\n",
        "contexts_token_ids_list_batch, contexts_input_masks_list_batch, \\\n",
        "responses_token_ids_list_batch, responses_input_masks_list_batch = (\n",
        "    torch.tensor(t, dtype=torch.long) for t in long_tensors)\n",
        "\n",
        "labels_batch = torch.tensor(labels_batch, dtype=torch.long)\n",
        "return contexts_token_ids_list_batch, contexts_input_masks_list_batch, \\\n",
        "                responses_token_ids_list_batch, responses_input_masks_list_batch, labels_batch"
      ],
      "metadata": {
        "id": "57vq-RkenHVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_input = context_transform(context)\n",
        "response_input = response_transform(candidate)\n",
        "\n",
        "\n",
        "\n",
        "torch.tensor(t, dtype=torch.long)"
      ],
      "metadata": {
        "id": "gCInxD8bqnyR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIa4XEMkpH7Fj+cC8e82NO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}