{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMBOoz6yW+GTBd7rgdpiBEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/Poly-Encoder"
      ],
      "metadata": {
        "id": "HXPA7-uDAIHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "c5f7462f-32a8-4a0e-bb1a-43bdcbbbe06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "099d07af-a13c-4163-94d6-fe27bfed7ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  5 06:16:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets folium==0.2.1"
      ],
      "metadata": {
        "id": "n-ZyBZPWfX5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "9f8289be-e17d-4d33-f825-ff55bf592728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 108 (delta 28), reused 20 (delta 8), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (108/108), 36.04 KiB | 9.01 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Poly-Encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzRLhnM-stL",
        "outputId": "78611f2f-46ee-47e0-cd7c-10fbd626b67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown -q --folder 1Ipr-aNF5ELMY0HTXAmeV26LlgktKUfmG"
      ],
      "metadata": {
        "id": "AcEZq-UQ-prG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture bi\n",
        "!python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16\n",
        "# !python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture cross"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch5QnDV6jVZj",
        "outputId": "0ab03620-d0e0-447c-f2c8-4967b2645719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(adam_epsilon=1e-08, architecture='poly', bert_model='klue/bert-base', dev_file='val_data_source.pickle', eval=False, eval_batch_size=32, fp16=False, fp16_opt_level='O1', gpu=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_contexts_length=128, max_grad_norm=1.0, max_response_length=32, model_type='bert', num_train_epochs=10.0, output_dir='chatbot_output/', poly_m=16, print_freq=100, seed=12345, test_file='test_data_source.pickle', train_batch_size=32, train_dir='감성대화챗봇데이터/', train_file='train_data_source.pickle', use_pretrain=False, warmup_steps=100, weight_decay=0.01)\n",
            "================================================================================\n",
            "Train dir: 감성대화챗봇데이터/\n",
            "Output dir: chatbot_output/\n",
            "================================================================================\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Embedding(32001, 768)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Print freq: 100 Eval freq: 639\n",
            "  0% 0/1278 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 271, in <module>\n",
            "    labels_batch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Poly-Encoder/encoder.py\", line 91, in forward\n",
            "    poly_code_ids = torch.arange(self.poly_m, dtype=torch.long).to(context_input_ids.device)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture bi --eval\n",
        "!python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --eval\n",
        "# !python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture poly --poly_m 16 --eval\n",
        "# !python3 run.py --bert_model bert_model/ --output_dir output_dstc7/ --train_dir dstc7/ --use_pretrain --architecture cross --eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POq7e5BjjXSr",
        "outputId": "d8abe4a8-3a4c-4482-f027-8ea0352c8adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(adam_epsilon=1e-08, architecture='bi', bert_model='bert_model/', eval=True, eval_batch_size=32, fp16=False, fp16_opt_level='O1', gpu=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_contexts_length=128, max_grad_norm=1.0, max_response_length=32, model_type='bert', num_train_epochs=10.0, output_dir='output_dstc7/', poly_m=0, print_freq=100, seed=12345, train_batch_size=32, train_dir='dstc7/', use_pretrain=True, warmup_steps=100, weight_decay=0.01)\n",
            "================================================================================\n",
            "Train dir: dstc7/\n",
            "Output dir: output_dstc7/\n",
            "================================================================================\n",
            "Loading parameters from output_dstc7/bi_0_pytorch_model.bin\n",
            "{'eval_loss': 2.34547645971179, 'R1': 0.481, 'R2': 0.581, 'R5': 0.685, 'R10': 0.77, 'MRR': 0.581299067078589}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/Poly-Encoder/output_dstc7 '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder'"
      ],
      "metadata": {
        "id": "Y1Qdur4wRAhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder/output_dstc7'"
      ],
      "metadata": {
        "id": "--6Br9QFwy3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertPreTrainedModel, BertConfig, BertModel, BertTokenizer, AutoModel\n",
        "from encoder import PolyEncoder\n",
        "\n",
        "PATH = '/content/Poly-Encoder/chatbot_output/poly_16_pytorch_model.bin'\n",
        "\n",
        "bert_name = 'klue/bert-base'\n",
        "bert_config = BertConfig.from_pretrained(bert_name)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
        "tokenizer.add_tokens(['\\n'], special_tokens=True)\n",
        "\n",
        "bert = BertModel.from_pretrained(bert_name, config=bert_config)\n",
        "\n",
        "model = PolyEncoder(bert_config, bert=bert, poly_m=16)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWnJ129TxQSl",
        "outputId": "7f5447fe-b2db-4c1b-bcf9-0935b94984d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "             'Sentences are passed as a list of string.',\n",
        "             'The quick brown fox jumps over the lazy dog.']"
      ],
      "metadata": {
        "id": "gd4e602pP2Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences = ['This framework generates embeddings for each input sentence']"
      ],
      "metadata": {
        "id": "rapB1afogMhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')"
      ],
      "metadata": {
        "id": "US9VUUhbQA8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    model_output = model.bert(**encoded_input)"
      ],
      "metadata": {
        "id": "4wtBKHLEQB_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdwrcO10Sm9i",
        "outputId": "f81924cb-84e1-476a-8fab-28c8a2dc5016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 25, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output[0][:,0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBSSzmh7eT62",
        "outputId": "b0c9c09a-7633-4a1f-875f-c0851e4182ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0931, -0.1231, -0.0292,  ..., -0.0014, -0.1432,  0.1350],\n",
              "        [ 0.0868, -0.1291, -0.0281,  ..., -0.0047, -0.1368,  0.1317],\n",
              "        [ 0.0876, -0.1231, -0.0293,  ..., -0.0074, -0.1360,  0.1305]])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = model.bert(**encoded_input)"
      ],
      "metadata": {
        "id": "KyYKB0CeiyYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output[0][:,0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrntQcELizgh",
        "outputId": "9b37a039-c29c-479c-f409-d84ef51df41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0931, -0.1231, -0.0292,  ..., -0.0014, -0.1432,  0.1350],\n",
              "        [ 0.0868, -0.1291, -0.0281,  ..., -0.0047, -0.1368,  0.1317],\n",
              "        [ 0.0876, -0.1231, -0.0293,  ..., -0.0074, -0.1360,  0.1305]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.dot_attention()"
      ],
      "metadata": {
        "id": "QogL8-GqSwMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import signature\n",
        "model.bert"
      ],
      "metadata": {
        "id": "F4egArTERpPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a_Io3tF1QLvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}