{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/Retrieval-Based-Chatbot/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXPA7-uDAIHP"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXufVK0iRN3Z",
        "outputId": "fb878ffd-5447-4ede-e574-f514ef5c91ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEJHV_6YR4k",
        "outputId": "884761a5-2070-4bf2-c604-64b5a16568cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul  7 00:28:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-ZyBZPWfX5m",
        "outputId": "3b6ef42d-8187-4751-b718-206ec29716ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 90.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 15.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 81.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 91.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 103.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 88.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 84.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 94.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[?25h  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets folium==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4lrYnocYNH4",
        "outputId": "bd574ada-694c-4575-ee1f-9b4d3a506da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Poly-Encoder'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 129 (delta 41), reused 20 (delta 8), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (129/129), 40.70 KiB | 13.57 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dotsnangles/Poly-Encoder.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LzRLhnM-stL",
        "outputId": "276c4322-b4a0-46fb-bb96-4c2df2eea068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Poly-Encoder\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Poly-Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AcEZq-UQ-prG"
      },
      "outputs": [],
      "source": [
        "!gdown -q --folder 1Ipr-aNF5ELMY0HTXAmeV26LlgktKUfmG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psjYArLBO1-C"
      },
      "outputs": [],
      "source": [
        "# \"--bert_model\", default='ckpt/pretrained/bert-small-uncased', type=str\n",
        "# \"--eval\", action=\"store_true\"\n",
        "# \"--model_type\", default='bert', type=str\n",
        "# \"--output_dir\", required=True, type=str\n",
        "# \"--train_dir\", default='data/ubuntu_data', type=str\n",
        "# \"--train_file\", default='data/ubuntu_data', type=str\n",
        "# \"--dev_file\", default='data/ubuntu_data', type=str\n",
        "# \"--test_file\", default='data/ubuntu_data', type=str\n",
        "\n",
        "# \"--use_pretrain\", action=\"store_true\"\n",
        "# \"--architecture\", required=True, type=str, help='[poly, bi, cross]'\n",
        "\n",
        "# \"--max_contexts_length\", default=128, type=int\n",
        "# \"--max_response_length\", default=32, type=int\n",
        "# \"--train_batch_size\", default=32, type=int, help=\"Total batch size for training.\"\n",
        "# \"--eval_batch_size\", default=32, type=int, help=\"Total batch size for eval.\"\n",
        "# \"--print_freq\", default=100, type=int, help=\"Log frequency\"\n",
        "\n",
        "# \"--poly_m\", default=0, type=int, help=\"Number of m of polyencoder\"\n",
        "\n",
        "# \"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\"\n",
        "# \"--weight_decay\", default=0.01, type=float\n",
        "# \"--warmup_steps\", default=100, type=float\n",
        "# \"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\"\n",
        "# \"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\"\n",
        "\n",
        "# \"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        "# '--seed', type=int, default=12345, help=\"random seed for initialization\"\n",
        "# '--gradient_accumulation_steps', type=int, default=1, help=\"Number of updates steps to accumulate before performing a backward/update pass.\"\n",
        "\n",
        "# \"--fp16\", action=\"store_true\", help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"\n",
        "\n",
        "# \"--fp16_opt_level\", type=str, default=\"O1\", help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\" \"See details at https://nvidia.github.io/apex/amp.html\"\n",
        "# '--gpu', type=int, default=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 run.py \\\n",
        "# \\\n",
        "# --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' \\\n",
        "# --train_dir '감성대화챗봇데이터/' \\\n",
        "# --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' \\\n",
        "# --architecture poly --poly_m 16 \\\n",
        "# \\\n",
        "# --num_train_epochs 10 \\\n",
        "# \\\n",
        "# --train_batch_size 4 \\\n",
        "# --eval_batch_size 4 \\\n",
        "# --gradient_accumulation_steps 1 \\\n",
        "# \\\n",
        "# --print_freq 800 \\ \n",
        "# \\\n",
        "# --max_contexts_length 256 --max_response_length 128"
      ],
      "metadata": {
        "id": "mqEuPskv5T1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch5QnDV6jVZj",
        "outputId": "87eb6d93-75fc-49a7-f02c-62cad4d1e31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(adam_epsilon=1e-08, architecture='poly', bert_model='klue/bert-base', dev_file='val_data_source.pickle', eval=False, eval_batch_size=4, fp16=False, fp16_opt_level='O1', gpu=0, gradient_accumulation_steps=1, learning_rate=5e-05, max_contexts_length=256, max_grad_norm=1.0, max_response_length=128, model_type='bert', num_train_epochs=10.0, output_dir='chatbot_output/', poly_m=16, print_freq=200, seed=12345, test_file='test_data_source.pickle', train_batch_size=4, train_dir='감성대화챗봇데이터/', train_file='train_data_source.pickle', use_pretrain=False, warmup_steps=100, weight_decay=0.01)\n",
            "Downloading: 100% 243k/243k [00:00<00:00, 1.33MB/s]\n",
            "Downloading: 100% 125/125 [00:00<00:00, 158kB/s]\n",
            "Downloading: 100% 289/289 [00:00<00:00, 325kB/s]\n",
            "Downloading: 100% 425/425 [00:00<00:00, 488kB/s]\n",
            "================================================================================\n",
            "Train dir: 감성대화챗봇데이터/\n",
            "Output dir: chatbot_output/\n",
            "================================================================================\n",
            "Downloading: 100% 424M/424M [00:05<00:00, 74.5MB/s]\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Print freq: 200 Eval freq: 1000\n",
            "  2% 200/10220 [00:40<33:51,  4.93it/s]200 3.566680881452029\n",
            "  4% 400/10220 [01:20<33:05,  4.95it/s]400 2.4550624050942336\n",
            "  6% 600/10220 [02:01<32:22,  4.95it/s]600 2.004398601180163\n",
            "  8% 800/10220 [02:41<31:41,  4.95it/s]800 1.8043795053215155\n",
            " 10% 1000/10220 [03:21<31:00,  4.95it/s]1000 1.6533432422512213\n"
          ]
        }
      ],
      "source": [
        "!python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --num_train_epochs 10 --train_batch_size 4 --eval_batch_size 4 --gradient_accumulation_steps 1 --print_freq 200 --max_contexts_length 256 --max_response_length 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POq7e5BjjXSr"
      },
      "outputs": [],
      "source": [
        "# !python3 run.py --bert_model 'klue/bert-base' --output_dir 'chatbot_output/' --train_dir '감성대화챗봇데이터/' --train_file 'train_data_source.pickle' --dev_file 'val_data_source.pickle' --test_file 'test_data_source.pickle' --architecture poly --poly_m 16 --eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1Qdur4wRAhb"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/Poly-Encoder/output_dstc7 '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--6Br9QFwy3N"
      },
      "outputs": [],
      "source": [
        "# PATH = '/content/drive/MyDrive/Data Science/알파코 딥러닝 부트캠프/프로젝트/Poly Encoder/output_dstc7'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6l10DWcY7hxA5mcD6Uw3Q",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}